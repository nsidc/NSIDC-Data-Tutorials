{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src='./img/nsidc_logo.png'/>\n",
    "</center>\n",
    "\n",
    "\n",
    "# **Download, Crop, Resample and Plot Multiple GeoTIFFs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Tutorial Overview**\n",
    "\n",
    "This tutorial guides us through programmatically accessing and downloading NSIDC DAAC data to our local computer. Then cropping and resampling one GeoTIFF based on the extent and and pixel size of another GeoTIFF, then plotting one on top of the other. \n",
    "\n",
    "We use two data sets from the NASA [MEaSUREs](https://nsidc.org/data/measures) (Making Earth System data records for Use in Research Environments) program as an example:\n",
    "\n",
    "* [MEaSUREs Greenland Ice Mapping Project (GrIMP) Digital Elevation Model from GeoEye and WorldView Imagery, Version 2](https://nsidc.org/data/nsidc-0715/versions/2)\n",
    "* [MEaSUREs Greenland Ice Velocity: Selected Glacier Site Velocity Maps from InSAR, Version 4](https://nsidc.org/data/nsidc-0481/versions/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Credits**\n",
    "\n",
    "Jennifer Roebuck contributed to this tutorial\n",
    "\n",
    "For questions regarding the notebook, or to report problems, please create a new issue in the [NSIDC-Data-Tutorials repo](https://github.com/nsidc/NSIDC-Data-Tutorials/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objectives** \n",
    "\n",
    "1. Use the `earthaccess` library for authentication and to programmatically apply spatial and temporal filters to an NSIDC DAAC data set and download the matching files. \n",
    "2. Use the `gdal` and `osr` modules from the `osgeo` package to crop and resample one GeoTIFF based on the extent and pixel size of another GeoTIFF.\n",
    "3. Use `rasterio` and `matplotlib` libraries to overlay one GeoTIFF on top of another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prerequisites**\n",
    "\n",
    "To run this tutorial we will need an Earthdata Login for authentication and downloading the data. It is completely free. If we don't have one, we can register for one [here](https://urs.earthdata.nasa.gov/). We recommend using a .netrc file for storing our Earthdata Login username and password, instructions for setting one up can be found in Step 1 in this [Programmatic Data Access Guide](https://nsidc.org/data/user-resources/help-center/programmatic-data-access-guide#anchor-0). If we don't want to set one up, we will be prompted for our username and password during the tutorial.\n",
    "\n",
    "A basic understanding of python may also be helpful for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example of end product**\n",
    "\n",
    "At the end of this tutorial, we will have produced a figure similar to the one below, which overlays velocity data on top of a digital elevation model:\n",
    "\n",
    "<center>\n",
    "    <img src='./img/example_geotiff_plot.png'/>\n",
    "</center>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time requirement**\n",
    "\n",
    "This tutorial will take approximately 30 minutes to complete. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Tutorial Steps**\n",
    "\n",
    "### **Import libraries and classes**\n",
    "\n",
    "We will use the following libraries:\n",
    "1. `earthaccess` to authenticate, search and download NSIDC DAAC data \n",
    "2. `os` to list all the files we have downloaded \n",
    "3. `osgeo.gdal` to crop and resample one of the GeoTIFFs \n",
    "4. `rasterio`, `affine`, and `numpy` to read the GeoTIFFs and set up a grid for plotting the data. \n",
    "5. `matplotlib` for plotting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Authentication**\n",
    "\n",
    "We need to set up our authentication using our Earthdata Login credentials. If we have a .netrc we can just run the cell below and it will automatically authenticate. If we don't have a .netrc we will be prompted for our Earthdata Login username and password. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Search for data using spatial and temporal filters**\n",
    "This tutorial assumes we already know which data sets we would like to download, that have data in GeoTIFF format. Each data set at NSIDC has a data set ID associated with it. We will look at two data sets focused on Greenland, a Digital Elevation Model (DEM) and velocity at glacier sites and will use the `earthaccess` library and the following filters to search for granules within these data sets:\n",
    "\n",
    "* `short_name` - this is the data set ID e.g., NSIDC-0715, NSIDC-0481. Can be found in the data set title on the data set landing page\n",
    "* `version` - data set version number, also included in the data set title\n",
    "* `cloud_hosted` - NSIDC is in the process of migrating data sets to the cloud. The data sets we are interested in are currently still archived on-prem so will set this to False.\n",
    "* `bounding_box` - sets a spatial filter by specifying latitude and longitude in the following order: W, S, E, and N.\n",
    "* `temporal` - sets a temporal filter by specifying a start and end date in the format YYYY-MM-DD.\n",
    "* `count` - this sets the maximum number of granules that will be returned in the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for DEM files\n",
    "results_dem = earthaccess.search_data(\n",
    "    short_name='NSIDC-0715',\n",
    "    version='2',\n",
    "    cloud_hosted=False,\n",
    "    bounding_box=(-33.45,68.29,-31.41,69.26),\n",
    "    temporal=('2015-12-01','2015-12-31'),\n",
    "    count=100\n",
    ")\n",
    "\n",
    "#Search for velocity data \n",
    "results_vel = earthaccess.search_data(\n",
    "    short_name='NSIDC-0481',\n",
    "    version='4',\n",
    "    cloud_hosted=False,\n",
    "    bounding_box=(-33.45,68.29,-31.41,69.26),\n",
    "    temporal=('2017-01-01','2017-12-31'),\n",
    "    count=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download the data**\n",
    "Now we have found granules that meet our search criteria we can download them to an 'outputs' folder using `earthaccess`. Note that for these particular data sets within each granule there are multiple files. So even though 1 granule was found for the DEM data set, 6 files will be downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up an outputs folder to download the data to\n",
    "path = str(os.getcwd() + '/outputs')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "#Download the DEM granules \n",
    "dem_files = earthaccess.download(results_dem, path)\n",
    "\n",
    "#Download the velocity granules\n",
    "vel_files = earthaccess.download(results_vel, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check the files that have been downloaded**\n",
    "We will list all the DEM and velocity files that were downloaded, as this is needed for the next steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(path)\n",
    "\n",
    "print('Files in ', path)\n",
    "\n",
    "for x in dir_list:\n",
    "    if x.endswith('.tif'):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Select and read in the DEM file and velocity file**\n",
    "\n",
    "Based on the list of filenames above, we will select the files that we wish to plot and input them into the cell below. We will use the 'browse' file of the DEM tile, as that provides the best continuous surface for visual display. For the velocity we will plot the velocity magnitude, which is denoted by 'vv' in the filename, and we will plot the velocity covering the time period 07 August to 18 August 2017. \n",
    "\n",
    "We will be cropping the DEM file to the extent of the velocity file, so we will also set a filename for the cropped DEM file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_fp = str(path + '/TSX_E68.80N_07Aug17_18Aug17_19-41-22_vv_v04.0.tif')\n",
    "\n",
    "dem_fp = str(path + '/tile_4_2_30m_browse_v02.0.tif')\n",
    "\n",
    "dem_crop = str(path + '/dem_crop_100.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Crop and resample DEM file based on velocity file extent and pixel size**\n",
    "\n",
    "We will use `gdal` to read the velocity file and get the extent and pixel size, and we will use `osr` to get the projection information. We will then use this information to crop and downsample the DEM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_raster = gdal.Open(vel_fp)\n",
    "geoTransform = vel_raster.GetGeoTransform()\n",
    "proj=osr.SpatialReference(wkt=vel_raster.GetProjection())\n",
    "epsg = 'EPSG:' + proj.GetAttrValue('AUTHORITY',1)\n",
    "\n",
    "pixelSizeX = geoTransform[1]\n",
    "pixelSizeY = geoTransform[5]\n",
    "minx = geoTransform[0]\n",
    "maxy = geoTransform[3]\n",
    "maxx = minx + pixelSizeX * vel_raster.RasterXSize\n",
    "miny = maxy + pixelSizeY * vel_raster.RasterYSize\n",
    "\n",
    "kwargs = { 'format': 'GTiff', 'outputBounds': [minx, miny, maxx, maxy], 'outputBoundsSRS': epsg, 'xRes': pixelSizeX, 'yRes': pixelSizeY}\n",
    "ds = gdal.Warp(dem_crop, dem_fp, **kwargs)\n",
    "ds=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set up the grids to plot the DEM and velocity data**\n",
    "To plot the cropped and downsampled DEM with the velocity data, we need to set up a grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in subsetted and resampled DEM\n",
    "dem_src = rasterio.open(dem_crop)\n",
    "\n",
    "# print out metadata information\n",
    "for k in dem_src.meta:\n",
    "    print(k,dem_src.meta[k])\n",
    "\n",
    "# Retrieve the affine transformation\n",
    "if isinstance(dem_src.transform, Affine):\n",
    "     transform = dem_src.transform\n",
    "else:\n",
    "     transform = dem_src.affine\n",
    "\n",
    "N = dem_src.width\n",
    "M = dem_src.height\n",
    "dx = transform.a\n",
    "dy = transform.e\n",
    "minx = transform.c\n",
    "maxy = transform.f\n",
    "\n",
    "# Read the image data, flip upside down if necessary\n",
    "dem_crop_in = dem_src.read(1)\n",
    "if dy < 0:\n",
    "    dy = -dy\n",
    "    dem_crop_in = np.flip(dem_crop_in, 0)\n",
    "\n",
    "#Uncomment the line below if you wish to see the min/max DEM values\n",
    "#print('Data minimum, maximum = ', np.amin(data_in), np.amax(data_in))\n",
    "\n",
    "# Generate X and Y grid locations\n",
    "xdata = minx + dx/2 + dx*np.arange(N)\n",
    "ydata = maxy - dy/2 - dy*np.arange(M-1,-1,-1)\n",
    "\n",
    "dem_extent = [xdata[0], xdata[-1], ydata[0], ydata[-1]]\n",
    "\n",
    "### read in the velocity data\n",
    "vel_data = rasterio.open(vel_fp)\n",
    "\n",
    "for k in vel_data.meta:\n",
    "    print(k,vel_data.meta[k])\n",
    "\n",
    "# Retrieve the affine transformation\n",
    "if isinstance(vel_data.transform, Affine):\n",
    "     transform = vel_data.transform\n",
    "else:\n",
    "     transform = vel_data.affine\n",
    "\n",
    "N2 = vel_data.width\n",
    "M2 = vel_data.height\n",
    "dx2 = transform.a\n",
    "dy2 = transform.e\n",
    "minx2 = transform.c\n",
    "maxy2 = transform.f\n",
    "\n",
    "# Read the image data, flip upside down if necessary\n",
    "vel_in = vel_data.read(1)\n",
    "if dy2 < 0:\n",
    "    dy2 = -dy2\n",
    "    vel_in = np.flip(vel_in, 0)\n",
    "\n",
    "#Uncomment the line below if you wish to see the min/max velocity values\n",
    "#print('Data minimum, maximum = ', np.amin(vel_in), np.amax(vel_in))\n",
    "\n",
    "# Generate X and Y grid locations\n",
    "xdata2 = minx2 + dx2/2 + dx2*np.arange(N2)\n",
    "ydata2 = maxy2 - dy2/2 - dy2*np.arange(M2-1,-1,-1)\n",
    "\n",
    "vel_extent = [xdata2[0], xdata2[-1], ydata2[0], ydata2[-1]]\n",
    "\n",
    "#Need to mask the no data values in the velocity data\n",
    "vel_masked = np.ma.masked_where(vel_in == -1.0, vel_in, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot the DEM and velocity data**\n",
    "Now we can plot the DEM with the velocity data on top. We will set the transparency of the velocity layer so we can see the DEM underneath. There is also an option to save the figure as .png, we can uncomment the last line if we want to save the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,8))\n",
    "fig = plt.imshow(dem_crop_in, extent=dem_extent, origin='lower', cmap='gray')\n",
    "fig2 = plt.imshow(vel_masked, extent=vel_extent, origin='lower', cmap='terrain', alpha=0.8)\n",
    "plt.title('Velocity and DEM')\n",
    "plt.xlabel('X (km)')\n",
    "plt.ylabel('Y (km)')\n",
    "cb = plt.colorbar(fig2, shrink=0.5)\n",
    "cb.set_label('Velocity Magnitude (m/yr)')\n",
    "\n",
    "#Option to save the figure\n",
    "#plt.savefig(\"velocity.png\", dpi=300, bbox_inches='tight', pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Learning Outcomes**\n",
    "\n",
    "* Search and download NSIDC DAAC data using `earthaccess`\n",
    "* Crop and resample GeoTIFF using `gdal`\n",
    "* Overlay one GeoTIFF on another in a plot using `matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Additional Resources**\n",
    "\n",
    "* Further details on the `earthacess` library can be found [here](https://github.com/nsidc/earthaccess)\n",
    "* Further details on data available from NSIDC can be found [here](https://nsidc.org/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
