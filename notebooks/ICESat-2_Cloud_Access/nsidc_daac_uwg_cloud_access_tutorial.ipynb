{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91169d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center>\n",
    "<img src='./img/nsidc_logo.png'/>\n",
    "    \n",
    "# **Accessing and working with ICESat-2 data in the cloud**\n",
    "    \n",
    "</center>\n",
    "    \n",
    "\n",
    "## **1. Tutorial Overview**\n",
    "\n",
    "**Note: This is an updated version of the notebook that was presented to the NSIDC DAAC User Working Group in May 2022**\n",
    "\n",
    "This notebook demonstrates searching for cloud-hosted ICESat-2 data and directly accessing Land Ice Height (ATL06) granules from an Amazon Compute Cloud (EC2) instance using the `earthaccess` package. NASA data \"in the cloud\" are stored in Amazon Web Services (AWS) Simple Storage Service (S3) Buckets. **Direct Access** is an efficient way to work with data stored in an S3 Bucket when you are working in the cloud. Cloud-hosted granules can be opened and loaded into memory without the need to download them first. This allows you take advantage of the scalability and power of cloud computing. \n",
    "\n",
    "The Amazon Global cloud is divided into geographical regions.  To have direct access to data stored in a region, our compute instance - a virtual computer that we create to perform processing operations in place of using our own desktop or laptop - must be in the same region as the data.  This is a fundamental concept of _analysis in place_. **NASA cloud-hosted data is in Amazon Region us-west2.  So your compute instance must also be in us-west2.** If we wanted to use data stored in another region, to use direct access for that data, we would start a compute instance in that region.\n",
    "\n",
    "As an example data  collection, we use ICESat-2 Land Ice Height (ATL06) over the Juneau Icefield, AK, for March 2003. ICESat-2 data granules, including ATL06, are stored in HDF5 format. We demonstrate how to open an HDF5 granule and access data variables using `xarray`. Land Ice Heights are then plotted using `hvplot`. \n",
    "\n",
    "`earthaccess` is a package developed by Luis Lopez (NSIDC developer) to allow easy search of the NASA Common Metadata Repository (CMR) and download of NASA data collections.  It can be used for programmatic search and access for both _DAAC-hosted_ and _cloud-hosted_ data. It manages authenticating using Earthdata Login credentials which are then used to obtain the S3 tokens that are needed for S3 direct access. https://github.com/nsidc/earthaccess\n",
    "\n",
    "\n",
    "### **Credits**\n",
    "\n",
    "The notebook was created by Andy Barrett, NSIDC, updated by Jennifer Roebuck, NSIDC, and is based on notebooks developed by Luis Lopez and Mikala Beig, NSIDC.\n",
    "\n",
    "For questions regarding the notebook, or to report problems, please create a new issue in the [NSIDC-Data-Tutorials repo](https://github.com/nsidc/NSIDC-Data-Tutorials/issues).\n",
    "\n",
    "### **Learning Objectives**\n",
    "\n",
    "By the end of this demonstration you will be able to:  \n",
    "1. use `earthaccess` to search for ICESat-2 data using spatial and temporal filters and explore search results;  \n",
    "2. open data granules using direct access to the ICESat-2 S3 bucket;  \n",
    "3. load a HDF5 group into an `xarray.Dataset`;  \n",
    "4. visualize the land ice heights using `hvplot`.  \n",
    "\n",
    "### **Prerequisites**\n",
    "\n",
    "1. An Amazon Web Services (AWS) account. You will be accessing data in Amazon Web Services (AWS) Simple Storage Service (S3) buckets. This requires an AWS account, for details on how to set one up see [here](https://nsidc.org/data/user-resources/help-center/nasa-earthdata-cloud-data-access-guide#anchor-1).\n",
    "2. An EC2 instance in the us-west-2 region is set up. **NASA cloud-hosted data is in Amazon Region us-west2. So you also need an EC2 instance in the us-west-2 region.** An EC2 instance is a virtual computer that you create to perform processing operations in place of using your own desktop or laptop.  Details on how to set up an instance can be found [here](https://nsidc.org/data/user-resources/help-center/nasa-earthdata-cloud-data-access-guide#anchor-1).\n",
    "3. An Earthdata Login is required for data access. If you don't have one, you can register for one [here](https://urs.earthdata.nasa.gov/).\n",
    "4. A .netrc file, that contains your Earthdata Login credentials, in your home directory. The current recommended practice for authentication is to create a .netrc file in your home directory following [these instructions](https://nsidc.org/support/how/how-do-i-programmatically-request-data-services) (Step 1) and to use the .netrc file for authentication when required for data access during the tutorial.\n",
    "5. The *nsidc-tutorials* environment is setup and activated. This [README](https://github.com/nsidc/NSIDC-Data-Tutorials/blob/main/README.md) has setup instructions.\n",
    "\n",
    "### **Example of end product** \n",
    "At the end of this tutorial, the following figure will be generated:\n",
    "<center>\n",
    "<img src='./img/atl06_example_end_product.png'/>\n",
    "</center>\n",
    "\n",
    "### **Time requirement**\n",
    "\n",
    "Allow approximately 20 minutes to complete this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f31af",
   "metadata": {},
   "source": [
    "## **2. Tutorial steps**\n",
    "\n",
    "## Import Packages\n",
    "\n",
    "The first step in any `python` script or notebook is to import packages.  This tutorial requires the following packages:\n",
    "- `earthaccess`, which enables Earthdata Login authentication and retrieves AWS credentials; enables collection and granule searches; and S3 access;\n",
    "- `xarray`, used to load data;\n",
    "- `hvplot`, used to visualize land ice height data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b4c9e6",
   "metadata": {},
   "source": [
    "We are going to import the whole `earthaccess` package.\n",
    "\n",
    "We will also import the whole `xarray` package but use a standard short name `xr`, using the `import <package> as <short_name>` syntax.  We could use anything for a short name but `xr` is an accepted standard that most `xarray` users are familiar with.\n",
    "\n",
    "We only need the `xarray` module from `hvplot` so we import that using the `import <package>.<module>` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For searching NASA data\n",
    "import earthaccess\n",
    "\n",
    "# For reading data, analysis and plotting\n",
    "import xarray as xr\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae2994",
   "metadata": {},
   "source": [
    "## Authenticate\n",
    "\n",
    "The first step is to get the correct authentication that will allow us to get _cloud-hosted_ ICESat-2 data.  This is all done through Earthdata Login.  The `login` method also gets the correct AWS credentials.\n",
    "\n",
    "Login requires your Earthdata Login username and password. The `login` method will automatically search for these credentials as environment variables or in a `.netrc` file, and if those aren't available it will prompt us to enter our username and password. We use a `.netrc` strategy. A `.netrc` file is a text file located in our home directory that contains login information for remote machines.  If we don't have a `.netrc` file, `login` can create one for us.\n",
    "\n",
    "```\n",
    "earthaccess.login(strategy='interactive', persist=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7b582",
   "metadata": {},
   "source": [
    "## Search for ICESat-2 Collections\n",
    "\n",
    "`earthaccess` leverages the Common Metadata Repository (CMR) API to search for collections and granules.  [Earthdata Search](https://search.earthdata.nasa.gov/search) also uses the CMR API.\n",
    "\n",
    "We can use the `keyword` method for `collection_query` to search for ICESat-2 collections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80e935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Query = earthaccess.collection_query().keyword('ICESat-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3957627",
   "metadata": {},
   "source": [
    "The `hits()` method can be used to find out how many collections (both _DAAC-hosted_ and _cloud-hosted_) we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query.hits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86f3e8",
   "metadata": {},
   "source": [
    "We can see what these data collections are by _getting_ `ShortName` and `Versions`.  In this case, we'll just grab the first 10 results and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6bcea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = Query.fields(['ShortName', 'Version']).get(10)\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88357e5",
   "metadata": {},
   "source": [
    "The `get`, used above, returns a list of python dictionaries containing metadata `meta` and the two requested attribute fields from the Unified Metadata Model (UMM) entry for the collection `umm`.  The `meta` entry for each collection contains the following information.\n",
    "\n",
    "- `concept-id`, which is a unique id for the collection.  You can use the `concept_id` to search for data granules.\n",
    "- `granule-count`, the number of data granules in the collection. \n",
    "- `provider-id`, the id for DAAC responsible for the collection.  This information is also part of the `concept-id`.\n",
    "\n",
    "For the ICESat-2 search results there is a provider-id; `NSIDC_ECS` and `NSIDC_CPRD`. `NSIDC_ECS` which is for the _on-prem_ collections and `NSIDC_CPRD` is for the _cloud-hosted_ collections. \n",
    "\n",
    "The `umm` fields are `ShortName` and `Version`.  For ICESat-2, `ShortNames` are generally how different products are referred to.\n",
    "\n",
    "| ShortName | Product Description |\n",
    "|:-----------:|:---------------------|\n",
    "| ATL03 | ATLAS/ICESat-2 L2A Global Geolocated Photon Data |\n",
    "| ATL06 | ATLAS/ICESat-2 L3A Land Ice Height |\n",
    "| ATL07 | ATLAS/ICESat-2 L3A Sea Ice Height |\n",
    "| ATL08 | ATLAS/ICESat-2 L3A Land and Vegetation Height |\n",
    "| ATL09 | ATLAS/ICESat-2 L3A Calibrated Backscatter Profiles and Atmospheric Layer Characteristics |\n",
    "| ATL10 | ATLAS/ICESat-2 L3A Sea Ice Freeboard |\n",
    "| ATL11 | ATLAS/ICESat-2 L3B Slope-Corrected Land Ice Height Time Series |\n",
    "| ATL12 | ATLAS/ICESat-2 L3A Ocean Surface Height |\n",
    "| ATL13 | ATLAS/ICESat-2 L3A Along Track Inland Surface Water Data |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62d6f6",
   "metadata": {},
   "source": [
    "### Search for cloud-hosted data\n",
    "For most collections, to search for only data in the cloud, the `cloud_hosted` method can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = earthaccess.collection_query().keyword('ICESat-2').cloud_hosted(True)\n",
    "print(Query.hits())\n",
    "collections = Query.fields(['ShortName', 'Version']).get(10)\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df10797",
   "metadata": {},
   "source": [
    "## Search a data set using spatial and temporal filters \n",
    "\n",
    "We can use the `search_data` method to search for granules within a data set by location and time using spatial and temporal filters. In this example, we will search for data granules from the ATL06 verison 006 cloud-hosted data set over the Juneau Icefield, AK, for March and April 2020.\n",
    "\n",
    "The temporal range is identified with standard date strings, and latitude-longitude corners of a bounding box is specified.  Polygons and points, as well as shapefiles can also be specified.\n",
    "\n",
    "This will display the number of granules that match our search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name = 'ATL06',\n",
    "    version = '006',\n",
    "    cloud_hosted = True,\n",
    "    bounding_box = (-134.7,58.9,-133.9,59.2),\n",
    "    temporal = ('2020-03-01','2020-04-30'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc1b37",
   "metadata": {},
   "source": [
    "We'll get metadata for these 4 granules and display it.  The rendered metadata shows a download link, granule size and two images of the data.\n",
    "\n",
    "The download link is `https` and can be used download the granule to your local machine.  This is similar to downloading _DAAC-hosted_ data but in this case the data are coming from the Earthdata Cloud.  For NASA data in the Earthdata Cloud, there is no charge to the user for egress from AWS Cloud servers.  This is not the case for other data in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04370d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[display(r) for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810da59e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use Direct-Access to open, load and display data stored on S3\n",
    "\n",
    "Direct-access to data from an S3 bucket is a two step process.  First, the files are opened using the `open` method.  The `auth` object created at the start of the notebook is used to provide Earthdata Login authentication and AWS credentials.\n",
    "\n",
    "The next step is to load the data.  In this case, data are loaded into an `xarray.Dataset`.  Data could be read into `numpy` arrays or a `pandas.Dataframe`.  However, each granule would have to be read using a package that reads HDF5 granules such as `h5py`.  `xarray` does this all _under-the-hood_ in a single line but for a single group in the HDF5 granule, in this case land ice heights for the gt1l beam*.\n",
    "\n",
    "*ICESat-2 measures photon returns from 3 beam pairs numbered 1, 2 and 3 that each consist of a left and a right beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11205bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "files = earthaccess.open(results)\n",
    "ds = xr.open_dataset(files[1], group='/gt1l/land_ice_segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75881751",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282ce34",
   "metadata": {},
   "source": [
    "`hvplot` is an interactive plotting tool that is useful for exploring data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7386c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['h_li'].hvplot(kind='scatter', s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4335c8",
   "metadata": {},
   "source": [
    "## **3. Learning outcomes recap**\n",
    "\n",
    "We have learned how to:\n",
    "1. use `earthaccess` to search for ICESat-2 data using spatial and temporal filters and explore search results;\n",
    "2. open data granules using direct access to the ICESat-2 S3 bucket;\n",
    "3. load a HDF5 group into an xarray.Dataset;\n",
    "4. visualize the land ice heights using hvplot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ea6bd",
   "metadata": {},
   "source": [
    "## **4. Additional resources**\n",
    "\n",
    "For general information about NSIDC DAAC data in the Earthdata Cloud: \n",
    "\n",
    "[FAQs About NSIDC DAAC's Earthdata Cloud Migration](https://nsidc.org/data/user-resources/help-center/faqs-about-nsidc-daacs-earthdata-cloud-migration)\n",
    "\n",
    "[NASA Earthdata Cloud Data Access Guide](https://nsidc.org/data/user-resources/help-center/nasa-earthdata-cloud-data-access-guide)\n",
    "\n",
    "Additional tutorials and How Tos:\n",
    "\n",
    "[NASA Earthdata Cloud Cookbook](https://nasa-openscapes.github.io/earthdata-cloud-cookbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67c7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
