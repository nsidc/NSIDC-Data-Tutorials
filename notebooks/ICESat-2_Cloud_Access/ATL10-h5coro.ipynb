{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86eaecf-a612-4dbb-8bdc-5b5dfddf65b9",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "<center>\n",
    "<img src='./img/nsidc_logo.png'/>\n",
    "\n",
    "# **Using Coiled and h5coro to Produce ICESat-2 Sea Ice Height Time Series**\n",
    "\n",
    "</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101ae06-3984-435c-abcc-f6346d15069b",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## **1. Tutorial Introduction/Overview**\n",
    "\n",
    "Tutorial designed for the \"DAAC data access in the cloud hands-on experience\" session at the 2023 NSIDC DAAC User Working Group (UWG) Meeting. This is a copy of the `2_ATL07_timeseries` notebook for use with Coiled.\n",
    "\n",
    "\n",
    "TODOS:\n",
    "* Explain Coiled\n",
    "* Question for Luis: Why would I use the decorator function (` @coiled.function()`) vs:\n",
    "\n",
    "```\n",
    "cluster = coiled.Cluster(n_workers=20, region=\"us-west-2\")\n",
    "client = cluster.get_client()\n",
    "client\n",
    "```\n",
    "* How do we incorporate https://medium.com/coiled-hq/processing-a-250-tb-dataset-with-coiled-dask-and-xarray-574370ba5bde ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689b48a-89e1-44c9-a681-75a669286bb1",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Installing last versions from earthaccess and coiled\n",
    "\n",
    "**NOTE**: Restart the kernel and clean output after the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9700d441-441a-41fb-9ad8-7ea5eabec52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "#!pip install coiled==0.9.26\n",
    "\n",
    "!pip uninstall -y earthaccess\n",
    "!pip install git+https://github.com/nsidc/earthaccess.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b77eb5-d5ed-4ddd-8fb1-6c69618d7852",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## **2. Tutorial steps**\n",
    "\n",
    "Resoruces: each granule is approx 60-120 MB, A month of data for the Ross ocean returns 59 granules ~4.6 GB. We should use an instance preferable double the memory of the aprox data size we use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820a737-33f0-4470-b9a4-03c5c4f0354c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e79729-1b02-4ef5-aee1-8923690243da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_657/2950134805.py:8: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 2;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n",
       "    },    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.4\n"
     ]
    }
   ],
   "source": [
    "# For Coiled cloud compute\n",
    "#import coiled\n",
    "\n",
    "# For searching NASA data\n",
    "import earthaccess\n",
    "\n",
    "from h5coro import h5coro, s3driver\n",
    "import geopandas as gpd\n",
    "\n",
    "# For reading data, analysis and plotting\n",
    "#import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import hvplot.xarray\n",
    "\n",
    "#import pprint\n",
    "from affine import Affine\n",
    "#from pyproj import CRS\n",
    "\n",
    "from pqdm.threads import pqdm\n",
    "\n",
    "#print(coiled.__version__)\n",
    "print(earthaccess.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966ffa6-a5f2-4520-a8dc-f37678a2cf7a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### **Authenticate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47aa955-3d91-4418-85f9-5772f400f712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARTHDATA_USERNAME and EARTHDATA_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\n",
      "You're now authenticated with NASA Earthdata Login\n",
      "Using token with expiration date: 11/18/2023\n",
      "Using .netrc file for EDL\n"
     ]
    }
   ],
   "source": [
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da19f604-0288-4358-ab88-d18c986f7cc8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### **Search for ICESat-2 ATL07 data**\n",
    "\n",
    "Using spatial/temporal range from https://icesat-2-2023.hackweek.io/tutorials/sea_ice/1_sea_ice_tutorial.html :\n",
    "\n",
    "\n",
    "```\n",
    "# Spatial extent: Ross Sea, Antarctica\n",
    "spatial_extent = [-180, -78, -160, -74]\n",
    "\n",
    "# Time range\n",
    "date_range = ['2019-09-16','2019-09-16'] # first time period\n",
    "# date_range = ['2019-11-13','2019-11-13'] # second time period\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b6752-2968-4673-92e5-c69b2364948e",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "This code cell helps to avoid copying and pasting region tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2069528-d382-45ab-a865-a41593bc47a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = \"Ross Sea\"\n",
    "ross_sea = (-180, -78, -160, -74)\n",
    "antarctic = (-180, -90, 180, -60)\n",
    "this_region = antarctic if region == \"Antarctica\" else ross_sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61875e91-c8b4-4beb-9535-c3391d1fcc06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching year 2019 ...\n",
      "Granules found: 59\n",
      "Total: 59\n"
     ]
    }
   ],
   "source": [
    "atl10 = {}\n",
    "total_results = 0\n",
    "\n",
    "for year in range(2019,2020):\n",
    "    \n",
    "    print(f\"Searching year {year} ...\")\n",
    "    granules = earthaccess.search_data(\n",
    "        short_name = 'ATL10',\n",
    "        version = '006',\n",
    "        cloud_hosted = True,\n",
    "        bounding_box = this_region,\n",
    "        temporal = (f'{year}-09-01',f'{year}-09-30'),\n",
    "    )\n",
    "    total_results += len(granules)\n",
    "    atl10[str(year)] = granules\n",
    "print(f\"Total: {total_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aacb907-e255-4c60-9eb8-d00c552685f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#r = [display(r) for r in atl10[\"2019\"][0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6887297-2b02-4e76-9bc5-5e804c54c5d7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### **Extract freeboard segments**\n",
    "\n",
    "We now create a geopandas dataset from our results. \n",
    "\n",
    "Because ATL10 is not a gridded prduct we need to extract coordinates and variables from their groups inside the HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff0fab-e1ad-4426-b7eb-e8e4f048b144",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Open the files using the `open` method. \n",
    "\n",
    "The auth object created at the start of the notebook is used to provide Earthdata Login authentication and AWS credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0142dd34-21f5-48ac-825e-328e772ecaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Opening 59 granules, approx size: 4.6 GB\n",
      "using provider: NSIDC_CPRD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de21e0e9cd9f41e095adf5b53c92b4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4809432a8d483dbe1517c4cb296ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0d5ceab6c444d29470be0e160e53f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_tree = {}\n",
    "\n",
    "for year, granules in atl10.items():\n",
    "    file_tree[year] = earthaccess.open(granules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6636d273-25e6-451f-931f-c5a7ec52d721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ETag': '\"e123bb7ed68661d31fea92a0abdf8fc0-1\"', 'LastModified': datetime.datetime(2023, 6, 24, 0, 19, 44, tzinfo=tzutc()), 'size': 46754892, 'name': 'nsidc-cumulus-prod-protected/ATLAS/ATL10/006/2019/09/01/ATL10-02_20190901100614_09980401_006_02.h5', 'type': 'file', 'StorageClass': 'STANDARD_IA', 'VersionId': None, 'ContentType': 'binary/octet-stream'}\n"
     ]
    }
   ],
   "source": [
    "# files[0].f.s3.storage_options\n",
    "print(file_tree[\"2019\"][0].f.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60b5e090-1747-4cfc-bbd5-815e5df4020a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import h5py\n",
    "\n",
    "\n",
    "# with h5py.File(file_tree[\"2019\"][0],'r') as f:\n",
    "#     obj = f[\"gt1r\"]['freeboard_segment/delta_time']\n",
    "#     for attr, value in obj.attrs.items():\n",
    "#         print(f\"{attr}: {value}\")\n",
    "#     time = obj[:]\n",
    "    \n",
    "# time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbc9d0fe-9184-4f20-ac6c-38c98bcd88c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds = xr.open_dataset(file_tree[\"2019\"][0], group=\"gt1r/freeboard_segment/\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37de57-f225-4d50-8ac2-8d9b7b76d9f7",
   "metadata": {},
   "source": [
    "### Pre-warming the Coiled instance.\n",
    "\n",
    "Once we get to run this with Coiled it would be good to instantiate the cluster beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d605657-3cb8-4894-9adc-45f020d6ed41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @coiled.function(region=\"us-west-2\",\n",
    "#                  memory=\"16 GiB\")\n",
    "# def trivial(param):\n",
    "#     print(param)\n",
    "#     return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3f58418-0c0e-49ca-adfa-d3fe6b53c4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trivial(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270e1930-1908-48eb-a1a5-831fba89009a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Based on the READ function form Younghyun Koo for the sea ice tutorial at the IS2 hackweek\n",
    "\n",
    "# @coiled.function(region=\"us-west-2\",\n",
    "#                  memory=\"16 GiB\")\n",
    "\n",
    "# Modifications to streamline\n",
    "# - helper function for orinetation\n",
    "# - helper function to reformat credentials\n",
    "# - use datasets to read arrays\n",
    "# - add data to dictionary\n",
    "\n",
    "#from h5coro import h5coro, s3driver, filedriver\n",
    "from itertools import product\n",
    "#import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import gc\n",
    "    \n",
    "GPS_EPOCH = pd.to_datetime('1980-01-06 00:00:00')\n",
    "\n",
    "def get_strong_beams(f):\n",
    "    \"\"\"Returns ground track for strong beams based on IS2 orientation\"\"\"\n",
    "    orient  = f['orbit_info/sc_orient'][0]\n",
    "\n",
    "    if orient == 0:\n",
    "        return [f\"gt{i}l\" for i in [1, 2, 3]]\n",
    "    elif orient == 1:\n",
    "        return [f\"gt{i}r\" for i in [1, 2, 3]]\n",
    "    else:\n",
    "        raise KeyError(\"Spacecraft orientation neither forward nor backward\")\n",
    "\n",
    "\n",
    "def get_credentials(file):\n",
    "    \"\"\"Returns credentials dict with keys expected by h5coro\n",
    "    \n",
    "    TODO: could add as option for earthaccess\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"aws_access_key_id\": file.s3.storage_options[\"key\"],\n",
    "        \"aws_secret_access_key\": file.s3.storage_options[\"secret\"],\n",
    "        \"aws_session_token\": file.s3.storage_options[\"token\"]\n",
    "    }\n",
    "    \n",
    "    \n",
    "def read_atl10_local(files, executors):\n",
    "    \"\"\"Returns a consolidated GeoPandas dataframe for a set of ATL10 file pointers.\n",
    "    \n",
    "    Parameters:\n",
    "        files (list[S3FSFile]): list of authenticated fsspec file references to ATL10 on S3 (via earthaccess)\n",
    "        executors (int): number of threads\n",
    "    \n",
    "    \"\"\"\n",
    "    def read_atl10(file):\n",
    "        \"\"\"Reads datasets required for creating gridded freeboard from a single ATL10 file\n",
    "        \n",
    "        file: an authenticated fsspec file reference on S3 (returned by earthaccess)\n",
    "        \n",
    "        returns: a list of geopandas dataframes\n",
    "        \"\"\"\n",
    "        \n",
    "        # Open file object\n",
    "        f = h5coro.H5Coro(file.info()[\"name\"], s3driver.S3Driver, credentials=get_credentials(file))\n",
    "        \n",
    "        # Get strong beams based on orientation\n",
    "        ancillary_datasets = [\"orbit_info/sc_orient\", \"ancillary_data/atlas_sdp_gps_epoch\"]\n",
    "        f.readDatasets(datasets=ancillary_datasets, block=True)\n",
    "        strong_beams = get_strong_beams(f)\n",
    "        atlas_sdp_gps_epoch = f[\"ancillary_data/atlas_sdp_gps_epoch\"][:]\n",
    "        \n",
    "        # Create list of datasets to load\n",
    "        datasets = [\"freeboard_segment/latitude\",\n",
    "                    \"freeboard_segment/longitude\",\n",
    "                    \"freeboard_segment/delta_time\",\n",
    "                    \"freeboard_segment/seg_dist_x\",\n",
    "                    \"freeboard_segment/heights/height_segment_length_seg\",\n",
    "                    \"freeboard_segment/beam_fb_height\",\n",
    "                    \"freeboard_segment/heights/height_segment_type\"]\n",
    "        ds_list = [\"/\".join(p) for p in list(product(strong_beams, datasets))]\n",
    "        # Load datasets\n",
    "        f.readDatasets(datasets=ds_list, block=True)\n",
    "        \n",
    "        # Create a list of geopandas.DataFrames containing beams\n",
    "        tracks = []\n",
    "        for beam in strong_beams:\n",
    "            ds = {dataset.split(\"/\")[-1]: f[dataset][:] for dataset in ds_list if dataset.startswith(beam)}\n",
    "            \n",
    "            # Convert delta_time to datetime\n",
    "            ds[\"delta_time\"] = GPS_EPOCH + pd.to_timedelta(ds[\"delta_time\"]+atlas_sdp_gps_epoch, unit='s')\n",
    "\n",
    "            # Add beam identifier\n",
    "            ds[\"beam\"] = beam\n",
    "            \n",
    "            # Set fill values to NaN - assume 100 m as threshold\n",
    "            ds[\"beam_fb_height\"] = np.where(ds[\"beam_fb_height\"] > 100, np.nan, ds[\"beam_fb_height\"])\n",
    "            \n",
    "            geometry = gpd.points_from_xy(ds[\"longitude\"], ds[\"latitude\"])\n",
    "            del ds[\"longitude\"]\n",
    "            del ds[\"latitude\"]\n",
    "            \n",
    "            gdf = gpd.GeoDataFrame(ds, geometry=geometry, crs=\"EPSG:4326\")\n",
    "            gdf.dropna(axis=0, inplace=True)\n",
    "            tracks.append(gdf)\n",
    "\n",
    "#             gc.collect()\n",
    "        return tracks\n",
    "    \n",
    "    df = pqdm(files, read_atl10, n_jobs=executors)\n",
    "    combined = pd.concat([t[0] for t in df if type(t) is list])\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ffca4-1c56-4659-a255-1cd38c86484d",
   "metadata": {},
   "source": [
    "The idea would be to split each year into its own Dask worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc14401-66a6-44ba-b8f2-421f45e50c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04bf5e01f3840cd8afaca3773472ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add40e1ad1764bb2a16dbcfc8a67894f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ae02caffb849ed9b49a093acecc4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 17s, sys: 1min 3s, total: 3min 20s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tracks = read_atl10_local(file_tree[\"2019\"], executors=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4f577fc-7c75-456e-b7bb-2a4f45ab77c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_time</th>\n",
       "      <th>seg_dist_x</th>\n",
       "      <th>height_segment_length_seg</th>\n",
       "      <th>beam_fb_height</th>\n",
       "      <th>height_segment_type</th>\n",
       "      <th>beam</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>2019-09-01 11:10:21.645610094</td>\n",
       "      <td>2.720752e+07</td>\n",
       "      <td>20.290331</td>\n",
       "      <td>0.253510</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (11.39429 -64.01932)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>2019-09-01 11:10:21.647197247</td>\n",
       "      <td>2.720753e+07</td>\n",
       "      <td>19.569931</td>\n",
       "      <td>0.265972</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (11.39427 -64.01942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2019-09-01 11:10:21.648262024</td>\n",
       "      <td>2.720754e+07</td>\n",
       "      <td>16.069815</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (11.39426 -64.01948)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>2019-09-01 11:10:21.649195671</td>\n",
       "      <td>2.720755e+07</td>\n",
       "      <td>14.670819</td>\n",
       "      <td>0.303078</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (11.39424 -64.01954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>2019-09-01 11:10:21.650213718</td>\n",
       "      <td>2.720755e+07</td>\n",
       "      <td>14.671224</td>\n",
       "      <td>0.324290</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (11.39423 -64.01960)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69215</th>\n",
       "      <td>2019-09-29 21:27:06.509730577</td>\n",
       "      <td>3.355327e+07</td>\n",
       "      <td>44.508583</td>\n",
       "      <td>0.181769</td>\n",
       "      <td>7</td>\n",
       "      <td>gt1r</td>\n",
       "      <td>POINT (24.15736 -59.13850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69216</th>\n",
       "      <td>2019-09-29 21:27:06.512042761</td>\n",
       "      <td>3.355329e+07</td>\n",
       "      <td>39.595520</td>\n",
       "      <td>0.149934</td>\n",
       "      <td>7</td>\n",
       "      <td>gt1r</td>\n",
       "      <td>POINT (24.15733 -59.13835)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69217</th>\n",
       "      <td>2019-09-29 21:27:06.514954329</td>\n",
       "      <td>3.355331e+07</td>\n",
       "      <td>36.785496</td>\n",
       "      <td>0.146254</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1r</td>\n",
       "      <td>POINT (24.15730 -59.13817)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69218</th>\n",
       "      <td>2019-09-29 21:27:06.516793250</td>\n",
       "      <td>3.355332e+07</td>\n",
       "      <td>28.306177</td>\n",
       "      <td>0.137055</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1r</td>\n",
       "      <td>POINT (24.15727 -59.13805)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69219</th>\n",
       "      <td>2019-09-29 21:27:06.518787621</td>\n",
       "      <td>3.355333e+07</td>\n",
       "      <td>34.685585</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1r</td>\n",
       "      <td>POINT (24.15725 -59.13793)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205785 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         delta_time    seg_dist_x  height_segment_length_seg  \\\n",
       "1831  2019-09-01 11:10:21.645610094  2.720752e+07                  20.290331   \n",
       "1832  2019-09-01 11:10:21.647197247  2.720753e+07                  19.569931   \n",
       "1833  2019-09-01 11:10:21.648262024  2.720754e+07                  16.069815   \n",
       "1834  2019-09-01 11:10:21.649195671  2.720755e+07                  14.670819   \n",
       "1835  2019-09-01 11:10:21.650213718  2.720755e+07                  14.671224   \n",
       "...                             ...           ...                        ...   \n",
       "69215 2019-09-29 21:27:06.509730577  3.355327e+07                  44.508583   \n",
       "69216 2019-09-29 21:27:06.512042761  3.355329e+07                  39.595520   \n",
       "69217 2019-09-29 21:27:06.514954329  3.355331e+07                  36.785496   \n",
       "69218 2019-09-29 21:27:06.516793250  3.355332e+07                  28.306177   \n",
       "69219 2019-09-29 21:27:06.518787621  3.355333e+07                  34.685585   \n",
       "\n",
       "       beam_fb_height  height_segment_type  beam                    geometry  \n",
       "1831         0.253510                    1  gt1l  POINT (11.39429 -64.01932)  \n",
       "1832         0.265972                    1  gt1l  POINT (11.39427 -64.01942)  \n",
       "1833         0.276316                    1  gt1l  POINT (11.39426 -64.01948)  \n",
       "1834         0.303078                    1  gt1l  POINT (11.39424 -64.01954)  \n",
       "1835         0.324290                    1  gt1l  POINT (11.39423 -64.01960)  \n",
       "...               ...                  ...   ...                         ...  \n",
       "69215        0.181769                    7  gt1r  POINT (24.15736 -59.13850)  \n",
       "69216        0.149934                    7  gt1r  POINT (24.15733 -59.13835)  \n",
       "69217        0.146254                    1  gt1r  POINT (24.15730 -59.13817)  \n",
       "69218        0.137055                    1  gt1r  POINT (24.15727 -59.13805)  \n",
       "69219        0.117143                    1  gt1r  POINT (24.15725 -59.13793)  \n",
       "\n",
       "[5205785 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f17a22-5578-4dfb-a474-218741ac8a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 5205785 entries, 1831 to 69219\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Dtype         \n",
      "---  ------                     -----         \n",
      " 0   delta_time                 datetime64[ns]\n",
      " 1   seg_dist_x                 float64       \n",
      " 2   height_segment_length_seg  float32       \n",
      " 3   beam_fb_height             float32       \n",
      " 4   height_segment_type        int8          \n",
      " 5   beam                       object        \n",
      " 6   geometry                   geometry      \n",
      "dtypes: datetime64[ns](1), float32(2), float64(1), geometry(1), int8(1), object(1)\n",
      "memory usage: 506.4 MB\n"
     ]
    }
   ],
   "source": [
    "tracks.info(memory_usage='deep')  # what does this do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27844c4b-bdb2-431b-9c85-8afd5ed09f0d",
   "metadata": {},
   "source": [
    "### For future IO eficient operations we save the geodataframe as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2369070-532f-4b0a-a1d8-0e424d0701af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 5205785 entries, 1831 to 69219\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Dtype         \n",
      "---  ------                     -----         \n",
      " 0   delta_time                 datetime64[ns]\n",
      " 1   seg_dist_x                 float64       \n",
      " 2   height_segment_length_seg  float32       \n",
      " 3   beam_fb_height             float32       \n",
      " 4   height_segment_type        int8          \n",
      " 5   beam                       object        \n",
      " 6   geometry                   geometry      \n",
      "dtypes: datetime64[ns](1), float32(2), float64(1), geometry(1), int8(1), object(1)\n",
      "memory usage: 243.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tracks[\"delta_time\"] = tracks[\"delta_time\"].astype('datetime64[s]')\n",
    "tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47292a7-25e7-43a5-8c45-9fecfdb21c17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Casting from timestamp[ns] to timestamp[us] would lose data: 1567336221645610094",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtracks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43matl10-2019.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/geodataframe.py:1049\u001b[0m, in \u001b[0;36mGeoDataFrame.to_parquet\u001b[0;34m(self, path, index, compression, schema_version, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoPandas only supports using pyarrow as the engine for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_parquet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m passed instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m     )\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_parquet\n\u001b[0;32m-> 1049\u001b[0m \u001b[43m_to_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/geopandas/io/arrow.py:301\u001b[0m, in \u001b[0;36m_to_parquet\u001b[0;34m(df, path, index, compression, schema_version, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m path \u001b[38;5;241m=\u001b[39m _expand_user(path)\n\u001b[1;32m    300\u001b[0m table \u001b[38;5;241m=\u001b[39m _geopandas_to_arrow(df, index\u001b[38;5;241m=\u001b[39mindex, schema_version\u001b[38;5;241m=\u001b[39mschema_version)\n\u001b[0;32m--> 301\u001b[0m \u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pyarrow/parquet/core.py:3106\u001b[0m, in \u001b[0;36mwrite_table\u001b[0;34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, **kwargs)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3084\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ParquetWriter(\n\u001b[1;32m   3085\u001b[0m             where, table\u001b[38;5;241m.\u001b[39mschema,\n\u001b[1;32m   3086\u001b[0m             filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3104\u001b[0m             store_schema\u001b[38;5;241m=\u001b[39mstore_schema,\n\u001b[1;32m   3105\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m-> 3106\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   3108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(where):\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pyarrow/parquet/core.py:1092\u001b[0m, in \u001b[0;36mParquetWriter.write_table\u001b[0;34m(self, table, row_group_size)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTable schema does not match schema used to create file: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1088\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtable:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m vs. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1089\u001b[0m            \u001b[38;5;241m.\u001b[39mformat(table\u001b[38;5;241m.\u001b[39mschema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema))\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pyarrow/_parquet.pyx:1777\u001b[0m, in \u001b[0;36mpyarrow._parquet.ParquetWriter.write_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Casting from timestamp[ns] to timestamp[us] would lose data: 1567336221645610094"
     ]
    }
   ],
   "source": [
    "#tracks.to_parquet(\"atl10-2019.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112e199-cd11-4f80-bc4b-4682035e3d81",
   "metadata": {},
   "source": [
    "#### Geopandas Read function \n",
    "\n",
    "The function below extracts latitude, longitude, segment distance, segment length, surface type, and freeboard height. See the [NSIDC's ATL10 User Guide](https://nsidc.org/sites/default/files/documents/user-guide/atl10-v006-userguide.pdf) for more details on these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8379b-275e-40e6-ab4f-d66a8a0fb00e",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Grid track data\n",
    "\n",
    "This follows the processing steps described in the ATL20 - Gridded Sea Ice Freeboard - ATBD but gridding to a EASE-Grid v2 6.25 km grid.  Any projected coordinate system or grid could be chosen.  The procedure could be modified with extra QC steps or modifications.  **The world is your oyster - or [Aplacophoran](https://antarcticsun.usap.gov/science/4447/)**.\n",
    "\n",
    "The processing steps are:\n",
    "\n",
    "- remove non-ice and low quality segments \n",
    "- resample freeboard segments to a grid\n",
    "- calculate aggregate statistics\n",
    "    + mean segment length\n",
    "    + segment count\n",
    "    + length weighted mean freeboard\n",
    "    + length weighted standard deviation of freeboard\n",
    "    \n",
    "#### Grid Cell Mean Segment Length $\\bar{L}$\n",
    "\n",
    "$$\n",
    "\\bar{L}(x, y, D) = \\frac{\\sum L_i}{N}\n",
    "$$\n",
    "\n",
    "where $L_i$ is `/gtx/freeboard_beam_segment/height_segments/height_segment_length_seg`, $x$ and $y$ are projected coordinates for grid centers, and $D$ is day. \n",
    "\n",
    "#### Grid Cell Mean Freeboard $\\bar{h}$\n",
    "\n",
    "$$\n",
    "\\bar{h}(x, y, D) = \\frac{\\sum L_i h_i}{\\sum L_i}\n",
    "$$\n",
    "\n",
    "where $h_i$ is `gtx/freeboard_beam_segment/beam_freeboard/beam_fb_height`.\n",
    "\n",
    "#### Grid Cell Standard Deviation of Freeboard $\\sigma^2 (x, y, D)$\n",
    "\n",
    "$$\n",
    "\\sigma^2 (x, y, D) = \\frac{\\sum L_i (h_i)^2}{\\sum L_i} - \\bar{h}^2 (x, y, D)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63674b7-c92a-4bc1-818c-9dae0cf9cc69",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Resample Freeboard Segments to a Grid\n",
    "\n",
    "Following the ATL20 ATBD, we will use a _drop-in-the-bucket_ resampling scheme.  This is simple and relatively easy to implement.  More complex resampling schemes could be substituted.\n",
    "\n",
    "To demonstrate resampling we will resample freeboard segments to WGS84 / NSIDC EASE-Grid v2.0 South with a grid resolution of 6.25 km.  The EPSG code for the WGS84 / NSIDC EASE-Grid South coordinate reference system is [6932](https://epsg.org/crs_6932/WGS-84-NSIDC-EASE-Grid-2-0-South.html).\n",
    "\n",
    "We will use the standard 6.25 km grid.  To define the grid, we need the grid dimensions (nrows and ncols), the x and y projected coordinates of the upper-left corner of the upper-left grid cell, and the height and width of the grid cells in the same units as the projected coordinates.  In this case, the units are meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "427548f4-9adb-4cee-adc1-b721bddcb7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "easegrid2_epsg = 6932\n",
    "\n",
    "nrow = 2880\n",
    "ncol = 2880\n",
    "upper_left_x = -9000000.0\n",
    "upper_left_y = 9000000.0\n",
    "width = 10000.0\n",
    "height = -10000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0d70b-253b-4ced-a354-6c7a20637640",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The first step is to reproject the points from geodetic coordinates (latitude and longitude) to projected coordinates (x, y).  Because the data are in a `geopandas.DataFrame` we can use the `to_crs` method.  This takes an EPSG code either as a numeric value (`6932`) or as a string (`\"EPSG:6932\"`).\n",
    "\n",
    "You can see that the `POINT` objects in the `geometry` have changed from having latitudes and longitudes as coordinates to x and y in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78293c52-ad08-45a1-bd66-99b2eaade3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 162 ms, total: 418 ms\n",
      "Wall time: 417 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_time</th>\n",
       "      <th>seg_dist_x</th>\n",
       "      <th>height_segment_length_seg</th>\n",
       "      <th>beam_fb_height</th>\n",
       "      <th>height_segment_type</th>\n",
       "      <th>beam</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>2019-09-01 11:10:21.645610094</td>\n",
       "      <td>2.720752e+07</td>\n",
       "      <td>20.290331</td>\n",
       "      <td>0.253510</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568023.081 2818528.976)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>2019-09-01 11:10:21.647197247</td>\n",
       "      <td>2.720753e+07</td>\n",
       "      <td>19.569931</td>\n",
       "      <td>0.265972</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568019.787 2818518.673)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2019-09-01 11:10:21.648262024</td>\n",
       "      <td>2.720754e+07</td>\n",
       "      <td>16.069815</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568017.576 2818511.765)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>2019-09-01 11:10:21.649195671</td>\n",
       "      <td>2.720755e+07</td>\n",
       "      <td>14.670819</td>\n",
       "      <td>0.303078</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568015.636 2818505.708)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>2019-09-01 11:10:21.650213718</td>\n",
       "      <td>2.720755e+07</td>\n",
       "      <td>14.671224</td>\n",
       "      <td>0.324290</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568013.520 2818499.103)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        delta_time    seg_dist_x  height_segment_length_seg  \\\n",
       "1831 2019-09-01 11:10:21.645610094  2.720752e+07                  20.290331   \n",
       "1832 2019-09-01 11:10:21.647197247  2.720753e+07                  19.569931   \n",
       "1833 2019-09-01 11:10:21.648262024  2.720754e+07                  16.069815   \n",
       "1834 2019-09-01 11:10:21.649195671  2.720755e+07                  14.670819   \n",
       "1835 2019-09-01 11:10:21.650213718  2.720755e+07                  14.671224   \n",
       "\n",
       "      beam_fb_height  height_segment_type  beam  \\\n",
       "1831        0.253510                    1  gt1l   \n",
       "1832        0.265972                    1  gt1l   \n",
       "1833        0.276316                    1  gt1l   \n",
       "1834        0.303078                    1  gt1l   \n",
       "1835        0.324290                    1  gt1l   \n",
       "\n",
       "                            geometry  \n",
       "1831  POINT (568023.081 2818528.976)  \n",
       "1832  POINT (568019.787 2818518.673)  \n",
       "1833  POINT (568017.576 2818511.765)  \n",
       "1834  POINT (568015.636 2818505.708)  \n",
       "1835  POINT (568013.520 2818499.103)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tracks = tracks.to_crs(easegrid2_epsg)\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea27df-9bea-409f-a754-d945fb7ae01a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "A _Drop-in-the-Bucket_ resampling scheme collects points into the grid cells that they intersect with, and then calculates aggregate statistics for each grid cell using attributes associated with those points.\n",
    "\n",
    "We'll find the grid cell that contains each segment by calculating the row and column coordinates for each segment from the projected coordinates.  This is done by creating an _Affine_ transformation matrix for the grid.  The Affine matrix is just a matrix representation of the algebraic expressions to convert row and column indices of the grid to projected coordinates.  The equations below give the forward transformation from `(row, col)` to `(x, y)`. \n",
    "\n",
    "$$\n",
    "x = width * col + upper\\_left\\_x \\\\\n",
    "y = height * row + upper\\_left\\_y\n",
    "$$\n",
    "\n",
    "These are expressed in matrix form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "0\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "a & 0 & c \\\\\n",
    "0 & d & e \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "col \\\\\n",
    "row \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $a$ is $\\mathsf{width}$, $c$ is $\\mathsf{upper\\_left\\_x}$, $d$ is $height$, and $e$ is $upper\\_left\\_y$.\n",
    "\n",
    "```{note}\n",
    "The projected coordinate system we are using is a cartesian plane with the origin at the South Pole.  The `x` coordinates increase to the right, and `y` coordinates increase up.  For raster data, which includes grids and images, have the origin at the upper-left corner of the grid.  Column indices increase from right to left, and row indices increase from top to bottom.\n",
    "```\n",
    "\n",
    "We use the `affine` package to create a forward transformation matrix (`fwd`) using the grid parameters above.  To transform `(x, y)` projected coordinates to `(row, col)`, we can calculate the reverse transformation matrix using `~fwd`.\n",
    "\n",
    "`(row, col)` coordinates are still rational numbers.  We want an integer row and column indices for grid cells.  We can use the `floor` function to get integers.  `row` and `column` indices are zero based.\n",
    "\n",
    "We want to be able to leverage the `geopandas.Dataframe.groupby` functionality to collect points into grid cells, so we need a unique identifier to group the data.  We can calculate a unique cell index from `row` and `column` indices as follows:\n",
    "\n",
    "$$\n",
    "cell\\_index = row * ncol + col\n",
    "$$\n",
    "\n",
    "This is encapsulated in the function `get_grid_index`.  This function is then applied to the `geometry` of tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00314673-7229-4be9-8674-0f39c9f29baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grid_index(xy):\n",
    "    geotransform = (upper_left_x, width, 0., upper_left_y, 0., height)\n",
    "    fwd = Affine.from_gdal(*geotransform)\n",
    "    row, col = ~fwd * xy\n",
    "    return (np.floor(row) * ncol) + np.floor(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1022f35f-50fa-4179-91c6-a9eebf5b313c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 0 ns, total: 31.3 s\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tracks[\"grid_index\"] = [get_grid_index((x, y)) for x, y in zip(tracks.geometry.x, tracks.geometry.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf80a3a9-e179-425f-bad5-3cf4c33820d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_time</th>\n",
       "      <th>seg_dist_x</th>\n",
       "      <th>height_segment_length_seg</th>\n",
       "      <th>beam_fb_height</th>\n",
       "      <th>height_segment_type</th>\n",
       "      <th>beam</th>\n",
       "      <th>geometry</th>\n",
       "      <th>grid_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>2019-09-01 11:10:21.645610094</td>\n",
       "      <td>2.720752e+07</td>\n",
       "      <td>20.290331</td>\n",
       "      <td>0.253510</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568023.081 2818528.976)</td>\n",
       "      <td>2753898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>2019-09-01 11:10:21.647197247</td>\n",
       "      <td>2.720753e+07</td>\n",
       "      <td>19.569931</td>\n",
       "      <td>0.265972</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568019.787 2818518.673)</td>\n",
       "      <td>2753898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2019-09-01 11:10:21.648262024</td>\n",
       "      <td>2.720754e+07</td>\n",
       "      <td>16.069815</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568017.576 2818511.765)</td>\n",
       "      <td>2753898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>2019-09-01 11:10:21.649195671</td>\n",
       "      <td>2.720755e+07</td>\n",
       "      <td>14.670819</td>\n",
       "      <td>0.303078</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568015.636 2818505.708)</td>\n",
       "      <td>2753898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>2019-09-01 11:10:21.650213718</td>\n",
       "      <td>2.720755e+07</td>\n",
       "      <td>14.671224</td>\n",
       "      <td>0.324290</td>\n",
       "      <td>1</td>\n",
       "      <td>gt1l</td>\n",
       "      <td>POINT (568013.520 2818499.103)</td>\n",
       "      <td>2753898.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        delta_time    seg_dist_x  height_segment_length_seg  \\\n",
       "1831 2019-09-01 11:10:21.645610094  2.720752e+07                  20.290331   \n",
       "1832 2019-09-01 11:10:21.647197247  2.720753e+07                  19.569931   \n",
       "1833 2019-09-01 11:10:21.648262024  2.720754e+07                  16.069815   \n",
       "1834 2019-09-01 11:10:21.649195671  2.720755e+07                  14.670819   \n",
       "1835 2019-09-01 11:10:21.650213718  2.720755e+07                  14.671224   \n",
       "\n",
       "      beam_fb_height  height_segment_type  beam  \\\n",
       "1831        0.253510                    1  gt1l   \n",
       "1832        0.265972                    1  gt1l   \n",
       "1833        0.276316                    1  gt1l   \n",
       "1834        0.303078                    1  gt1l   \n",
       "1835        0.324290                    1  gt1l   \n",
       "\n",
       "                            geometry  grid_index  \n",
       "1831  POINT (568023.081 2818528.976)   2753898.0  \n",
       "1832  POINT (568019.787 2818518.673)   2753898.0  \n",
       "1833  POINT (568017.576 2818511.765)   2753898.0  \n",
       "1834  POINT (568015.636 2818505.708)   2753898.0  \n",
       "1835  POINT (568013.520 2818499.103)   2753898.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d09140a5-3544-44a4-9531-a8c83c1f4974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_segment_counts = tracks.groupby(\"grid_index\")[\"beam_fb_height\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22f1a761-2fa1-4700-8dc2-481b419ee2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid = np.zeros((nrow, ncol)).flatten()\n",
    "grid[cell_segment_counts.index.values.astype(int)] = cell_segment_counts\n",
    "grid = grid.reshape((nrow, ncol))\n",
    "#grid = np.where(grid > 0, grid, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b835ca6-b173-494b-86c1-d9a640c3fdda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 2880)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "70878819-d454-42df-b721-06661a22318d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2317.0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.min(), grid.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92549f7-1bb0-4373-b810-1813d450fb31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Assign to grid and calculate grid cell mean**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b2ef6-3e14-475e-b689-77bda4c1814e",
   "metadata": {},
   "source": [
    "## **3. Learning outcomes recap (optional)**\n",
    "\n",
    "Provide a brief summary of the learning outcomes of the tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87da360-fa68-43e6-993e-5d5098b70aed",
   "metadata": {},
   "source": [
    "## **4. Additional resources (optional)**\n",
    "\n",
    "List some additional resources for users to consult, if applicable/desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b3e1e-71e4-4aab-bdbe-4d33dbce01e9",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "### **When your tutorial is ready for review,  please read our [Contributor Guide](https://github.com/nsidc/NSIDC-Data-Tutorials/blob/main/contributor_guide.md) for next steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7019c-b0c8-4c96-a36c-9cb1d17b6303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
